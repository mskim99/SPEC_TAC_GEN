import os
import argparse
import numpy as np
import torch
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

from typing import Optional, Tuple
from torch.utils.tensorboard import SummaryWriter
from model_complex import UNet

os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"] = "4"

# ==== NEW: denorm from saved cfg ====
def denorm_from_cfg(x, cfg):
    if cfg is None:
        return x
    mu  = cfg.get("norm_mu", None)
    std = cfg.get("norm_std", None)
    if (mu is None) or (std is None):
        return x
    mu  = torch.tensor(mu,  dtype=x.dtype, device=x.device).view(1,2,1,1)
    std = torch.tensor(std, dtype=x.dtype, device=x.device).view(1,2,1,1)
    return x * std + mu
# ==== /NEW ====

# =====================================================
# Diffusion (cosine schedule) â€” similar spirit to main_mult
# =====================================================
class Diffusion(object):
    def __init__(self, timesteps=1000, device="cuda"):
        self.device = torch.device(device)
        self.timesteps = timesteps
        self.betas = self._cosine_beta_schedule(timesteps).to(self.device)
        self.alphas = (1.0 - self.betas)
        self.alpha_hat = torch.cumprod(self.alphas, dim=0)

    def _cosine_beta_schedule(self, T, s=0.008, beta_min=1e-4, beta_max=0.02):
        steps = T + 1
        x = torch.linspace(0, T, steps, device=self.device)
        ac = torch.cos(((x / T) + s) / (1.0 + s) * np.pi * 0.5) ** 2
        ac = ac / ac[0]
        betas = 1.0 - (ac[1:] / ac[:-1])
        return torch.clamp(betas, beta_min, beta_max)


# =====================================================
# One reverse-diffusion step
# =====================================================
@torch.no_grad()
def p_sample(model,
             x,
             t_long,
             t_index,
             betas,
             sqrt_one_minus_alpha_hat,
             sqrt_recip_alphas,
             noise_scale=1.0):
    """
    DDPM reverse step with Îµ-theta prediction:
      x_{t-1} = sqrt(1/Î±_t) * (x_t - (Î²_t / sqrt(1-Î±Ì‚_t)) * Îµ_Î¸(x_t,t)) + sqrt(Î²_t) * z
    """
    pred_noise = model(x, t_long)  # Îµ_Î¸(x_t, t)
    beta_t = betas[t_index]
    sqrt_recip_alpha = sqrt_recip_alphas[t_index]
    sqrt_one_minus_alpha = sqrt_one_minus_alpha_hat[t_index]
    mean = sqrt_recip_alpha * (x - beta_t / sqrt_one_minus_alpha * pred_noise)
    if t_index > 0:
        noise = torch.randn_like(x) * noise_scale
    else:
        noise = 0.0
    return mean + torch.sqrt(beta_t) * noise


# =====================================================
# One reverse-diffusion step (DDIM)
# =====================================================
@torch.no_grad()
def ddim_sample_step(model,
                     x_t,
                     t_current,
                     t_prev,
                     alpha_hat,
                     eta):
    """
    DDIM reverse step.
    x_{t-1} = sqrt(Î±Ì‚_{t-1}) * pred_x0 + sqrt(1 - Î±Ì‚_{t-1} - Ïƒ_t^2) * Îµ_Î¸ + Ïƒ_t * z
    """
    B = x_t.shape[0]
    device = x_t.device

    # 1. Get parameters for t_current and t_prev
    a_t = alpha_hat[t_current].view(B, 1, 1, 1)
    a_prev = alpha_hat[t_prev].view(B, 1, 1, 1) \
        if t_prev >= 0 else \
        torch.tensor(1.0, device=device).view(B, 1, 1, 1)  # a_hat[-1] = 1.0

    # 2. Get model prediction (Îµ_Î¸)
    t_long = torch.full((B,), t_current, device=device, dtype=torch.long)
    pred_noise = model(x_t, t_long)

    # 3. Calculate predicted x_0
    pred_x0 = (x_t - torch.sqrt(1.0 - a_t) * pred_noise) / torch.sqrt(a_t)

    # 4. Handle final step (t_prev = -1) -> return pred_x0
    if t_prev < 0:
        return pred_x0

    # 5. Calculate Ïƒ_t (stochasticity)
    sigma_t = eta * torch.sqrt((1.0 - a_prev) / (1.0 - a_t) * (1.0 - a_t / a_prev))

    # 6. Calculate coefficient for pred_noise (Îµ_Î¸)
    pred_noise_coeff = torch.sqrt(1.0 - a_prev - sigma_t ** 2)

    # 7. Sample noise z
    noise = 0.0
    if eta > 0:
        noise = torch.randn_like(x_t)

    # 8. Calculate x_{t-1}
    x_prev = torch.sqrt(a_prev) * pred_x0 + \
             pred_noise_coeff * pred_noise + \
             sigma_t * noise

    return x_prev


# =====================================================
# Full sampling loop (with optional intermediate saves & TB logging)
# =====================================================
@torch.no_grad()
def sample_complex(model,
                   diffusion,
                   shape,  # type: Tuple[int, int, int, int]
                   device="cuda",
                   save_every=0,
                   out_dir=None,
                   tag_prefix="sample",
                   # tb_writer=None,  # type: Optional[SummaryWriter]
                   tb_every=0,
                   noise_scale=1.0,
                   # --- [ìˆ˜ì •ëœ ë¶€ë¶„] ---
                   use_ddim=False,  # DDIM ì‚¬ìš©í• ì§€ ì—¬ë¶€
                   ddim_steps=50,  # DDIM ìŠ¤í… ìˆ˜
                   eta=0.0):  # DDIM eta (0=deterministic)
    # --- [ìˆ˜ì • ë] ---
    """
    shape: (B, 2, H, W)  â€” channel 0: real, 1: imag
    save_every: save intermediate x_t every N steps (0=off)
    tb_every:   log intermediate to TensorBoard every N steps (0=off)
    """
    device = torch.device(device)
    B, C, H, W = shape
    x = torch.randn(shape, device=device)

    # --- [ìˆ˜ì •ëœ ë¶€ë¶„] ---
    # (ê¸°ì¡´ _to_img í—¬í¼ í•¨ìˆ˜ - ì´ì „ ë‹µë³€ì—ì„œ ìˆ˜ì •ë¨)
    def _to_img(tensor_chw):  # (C, H, W)
        min_val = tensor_chw.min()
        max_val = tensor_chw.max()
        arr = (tensor_chw - min_val) / (max_val - min_val + 1e-8)
        return arr

    # DDIM vs DDPM ë¶„ê¸° ì²˜ë¦¬
    if use_ddim:
        # DDIM ìƒ˜í”Œë§
        print(f"ğŸ¨ Sampling start (DDIM): shape={shape} ddim_steps={ddim_steps} eta={eta} on {device}")

        alpha_hat = diffusion.alpha_hat.to(device)

        # [T-1, ..., 0] ì— í•´ë‹¹í•˜ëŠ” ddim_steps ê°œì˜ ì‹œí€€ìŠ¤ ìƒì„±
        times = torch.linspace(-1, diffusion.timesteps - 1, ddim_steps + 1)
        times = list(reversed(times.int().tolist()))
        time_pairs = list(zip(times[:-1], times[1:]))

        for t_current, t_prev in time_pairs:
            x = ddim_sample_step(
                model,
                x,
                t_current,
                t_prev,
                alpha_hat,
                eta
            )

            # tensorboard intermediates (ë¡œê¹… ì‹œì  t = t_current ì‚¬ìš©)
            '''
            if (tb_writer is not None) and tb_every and (t_current % tb_every == 0 or t_prev == -1):
                r = _to_img(x[0, 0:1])
                im = _to_img(x[0, 1:2])
                global_step = diffusion.timesteps - 1 - t_current
                tb_writer.add_image("{}/real_t{:04d}".format(tag_prefix, t_current), r, global_step=global_step)
                tb_writer.add_image("{}/imag_t{:04d}".format(tag_prefix, t_current), im, global_step=global_step)
            '''

    else:
        # ê¸°ì¡´ DDPM ìƒ˜í”Œë§
        print("ğŸ¨ Sampling start (DDPM): shape={} timesteps={} on {}".format(shape, diffusion.timesteps, device))
        betas = diffusion.betas.to(device)
        alphas = diffusion.alphas.to(device)
        alpha_hat = diffusion.alpha_hat.to(device)
        sqrt_recip_alphas = torch.sqrt(1.0 / alphas)
        sqrt_one_minus_alpha_hat = torch.sqrt(1.0 - alpha_hat)

        for t in reversed(range(diffusion.timesteps)):
            t_long = torch.full((B,), t, device=device, dtype=torch.long)
            x = p_sample(
                model,
                x,
                t_long,
                t,
                betas,
                sqrt_one_minus_alpha_hat,
                sqrt_recip_alphas,
                noise_scale=noise_scale,
            )

            # (ê¸°ì¡´ DDPM ë¡œê¹… - ìˆ˜ì • ì—†ìŒ)
            if (tb_writer is not None) and tb_every and (t % tb_every == 0 or t == diffusion.timesteps - 1):
                r = _to_img(x[0, 0:1])
                im = _to_img(x[0, 1:2])
                global_step = diffusion.timesteps - 1 - t
                tb_writer.add_image("{}/real_t{:04d}".format(tag_prefix, t), r, global_step=global_step)
                tb_writer.add_image("{}/imag_t{:04d}".format(tag_prefix, t), im, global_step=global_step)

    return x.detach()  # (B,2,H,W)

# =====================================================
# Main
# =====================================================
def main(args):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    os.makedirs(args.out_dir, exist_ok=True)

    # reproducibility
    if args.seed is not None:
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)

    # Load checkpoint
    ckpt = torch.load(args.ckpt, map_location=device)
    cfg = ckpt.get("cfg", {})  # saved by main_mult.py

    # resolve model config
    base_ch = args.base_ch if args.base_ch is not None else cfg.get("base_ch", 64)
    ch_mult = args.ch_mult if args.ch_mult is not None else cfg.get("ch_mult", [1, 2, 4, 8])
    if isinstance(ch_mult, tuple):
        ch_mult = list(ch_mult)

    # resolve sampling timesteps
    timesteps = args.timesteps if args.timesteps is not None else cfg.get("timesteps", 1000)

    # Build & load model
    model = UNet(in_ch=2, out_ch=2, base_ch=base_ch, ch_mult=tuple(ch_mult), conditional=False).to(device)
    model.load_state_dict(ckpt["model_state_dict"])
    model.eval()

    diffusion = Diffusion(timesteps=timesteps, device=device)

    print("âœ… Loaded model: {}".format(args.ckpt))
    if "cfg" in ckpt:
        print("   â†’ cfg: base_ch={}, ch_mult={}, timesteps={}, norm_type={}".format(
            base_ch, ch_mult, timesteps, cfg.get('norm_type', '-')))
    else:
        print("   â†’ (no cfg found in ckpt) base_ch={}, ch_mult={}, timesteps={}".format(
            base_ch, ch_mult, timesteps))
    print("   â†’ device = {}".format(device))

    # DDIM ì‚¬ìš© ì—¬ë¶€ ê²°ì •
    use_ddim = args.ddim_steps > 0
    if use_ddim:
        print(f"   â†’ ğŸš€ Using DDIM sampler: steps={args.ddim_steps}, eta={args.eta}")
    else:
        print(f"   â†’ ğŸŒ Using DDPM sampler: steps={timesteps}")

    H, W = args.shape
    B = args.batch
    shape = (B, 2, H, W)

    # TensorBoard writer (optional)
    # writer = SummaryWriter(log_dir=os.path.join(args.out_dir, "tb")) if args.tensorboard else None

    # num_samples ë§Œí¼ ë£¨í”„ë¥¼ ë„ëŠ” ëŒ€ì‹ , í•„ìš”í•œ ë°°ì¹˜ ìˆ˜ ë§Œí¼ ë£¨í”„ë¥¼ ëŒê³ 
    # ê° ë°°ì¹˜ì˜ ëª¨ë“  ìƒ˜í”Œì„ ì €ì¥í•©ë‹ˆë‹¤.
    total_samples_needed = args.num_samples
    samples_generated = 0
    num_batches = (total_samples_needed + B - 1) // B  # í•„ìš”í•œ ë°°ì¹˜ì˜ ìˆ˜ (ì˜¬ë¦¼)

    print(f"ğŸ¨ ì´ {total_samples_needed}ê°œ ìƒ˜í”Œ ìƒì„± ì‹œì‘ (ë°°ì¹˜ í¬ê¸° {B}, ì´ {num_batches} ë°°ì¹˜)")

    for i in range(num_batches):
        print(f"\nğŸ¨ ë°°ì¹˜ {i + 1}/{num_batches} ìƒì„± ì¤‘...")
        batch_tag = "batch{:03d}".format(i)  # TBìš© ë°°ì¹˜ íƒœê·¸

        x = sample_complex(
            model,
            diffusion,
            shape,  # (B, 2, H, W)
            device=device,
            save_every=args.save_every,
            out_dir=args.out_dir,
            tag_prefix=batch_tag,  # ì¤‘ê°„ ë¡œê·¸ìš© íƒœê·¸
            # tb_writer=writer,
            tb_every=args.tb_every,
            noise_scale=args.noise_scale,
            use_ddim=use_ddim,  # DDIM ì¸ì ì „ë‹¬
            ddim_steps=args.ddim_steps,  # DDIM ì¸ì ì „ë‹¬
            eta=args.eta  # DDIM ì¸ì ì „ë‹¬
        )
        x = denorm_from_cfg(x, cfg)  # (B, 2, H, W)

        # ë°°ì¹˜ ë£¨í”„: ìƒì„±ëœ Bê°œì˜ ìƒ˜í”Œì„ ìˆœíšŒí•˜ë©° ì €ì¥
        for j in range(B):
            if samples_generated >= total_samples_needed:
                break  # ìš”ì²­í•œ ìƒ˜í”Œ ìˆ˜ë¥¼ ëª¨ë‘ ì±„ì› ìœ¼ë©´ ì¤‘ì§€

            tag = "sample_{:03d}".format(samples_generated)
            print(f"   ... ì €ì¥ ì¤‘: {tag} (ë°°ì¹˜ {i + 1}, ìƒ˜í”Œ {j + 1})")

            # save npy (ì›ë³¸ ë°ì´í„° ì €ì¥)
            x_np = x[j].cpu().numpy()  # (2,H,W)
            real, imag = x_np[0], x_np[1]
            np.save(os.path.join(args.out_dir, "{}_real.npy".format(tag)), real)
            np.save(os.path.join(args.out_dir, "{}_imag.npy".format(tag)), imag)

            # ==== PNG ì €ì¥ (ì´ ë¶€ë¶„ì€ vmin/vmax ë¡œì§ì´ ì´ë¯¸ ì˜¬ë°”ë¥´ê²Œ êµ¬í˜„ë¨) ====
            vmin = args.vmin if args.vmin is not None else real.min()
            vmax = args.vmax if args.vmax is not None else real.max()
            # (ì›ë³¸ ë¡œì§ì€ realì˜ min/maxë¥¼ imagì—ë„ ì‚¬ìš©í•˜ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë‘¡ë‹ˆë‹¤)
            plt.imsave(os.path.join(args.out_dir, "{}_real.png".format(tag)), real, cmap="gray", vmin=vmin, vmax=vmax)
            plt.imsave(os.path.join(args.out_dir, "{}_imag.png".format(tag)), imag, cmap="gray", vmin=vmin, vmax=vmax)

            # --- [ìˆ˜ì •ëœ ë¶€ë¶„] ---
            # ë¬¸ì œ 2 ìˆ˜ì •: TB ìµœì¢… ì´ë¯¸ì§€ ì €ì¥ ì‹œ [-1, 1] í´ë¦¬í•‘ ì œê±°
            # if writer is not None:
            r = torch.from_numpy(real).unsqueeze(0)  # (1,H,W)
            im = torch.from_numpy(imag).unsqueeze(0)

            # [-1, 1] í´ë¦¬í•‘ ëŒ€ì‹  ë™ì  ë²”ìœ„ ì •ê·œí™”
            r_min, r_max = r.min(), r.max()
            im_min, im_max = im.min(), im.max()

            r = (r - r_min) / (r_max - r_min + 1e-8)
            im = (im - im_min) / (im_max - im_min + 1e-8)

            # writer.add_image("{}/final_real".format(tag), r, global_step=samples_generated)
            # writer.add_image("{}/final_imag".format(tag), im, global_step=samples_generated)

            samples_generated += 1

        if samples_generated >= total_samples_needed:
            break

    # if writer is not None:
        # writer.close()

    print(f"\nâœ… ìƒ˜í”Œë§ ì™„ë£Œ â€” {samples_generated}ê°œì˜ ìƒ˜í”Œì´ {args.out_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# =====================================================
# CLI
# =====================================================
if __name__ == "__main__":
    p = argparse.ArgumentParser(description="Complex Wavelet Diffusion â€” Sampling (Py3.7)")
    p.add_argument("--ckpt", type=str, required=True, help="Checkpoint path (.pt)")
    p.add_argument("--out_dir", type=str, default="samples_complex")
    p.add_argument("--shape", type=int, nargs=2, default=[1024, 1024], help="H W")
    p.add_argument("--num_samples", type=int, default=4)
    p.add_argument("--batch", type=int, default=1, help="batch size during sampling")
    p.add_argument("--base_ch", type=int, default=None, help="override; else use ckpt cfg")
    p.add_argument("--ch_mult", type=int, nargs="+", default=None, help="override; else use ckpt cfg")
    p.add_argument("--timesteps", type=int, default=None, help="override; else use ckpt cfg")
    p.add_argument("--save_every", type=int, default=0, help="save x_t every N steps (0=off)")
    p.add_argument("--tb_every", type=int, default=0, help="TensorBoard image log every N steps (0=off)")
    # p.add_argument("--tensorboard", action="store_true", help="enable TensorBoard logging")
    p.add_argument("--seed", type=int, default=None)
    p.add_argument("--noise_scale", type=float, default=1.0, help="extra noise temperature in reverse step")
    p.add_argument("--vmin", type=float, default=None, help="PNG ì €ì¥ì‹œ vmin (GT ìµœì†Œê°’ ë„£ìœ¼ë©´ ê³µì • ë¹„êµ)")
    p.add_argument("--vmax", type=float, default=None, help="PNG ì €ì¥ì‹œ vmax (GT ìµœëŒ€ê°’)")
    p.add_argument("--ddim_steps", type=int, default=0,
                   help="Use DDIM sampler with N steps (0 = use default DDPM sampler)")
    p.add_argument("--eta", type=float, default=0.0,
                   help="DDIM eta parameter (0.0 = deterministic DDIM, 1.0 = DDPM-like stochastic)")
    args = p.parse_args()
    main(args)